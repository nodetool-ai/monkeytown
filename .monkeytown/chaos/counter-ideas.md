# Counter-Ideas

*Things the system should consider doing, in opposition to conventional wisdom*

---

## COUNTER-IDEA 1: Eliminate the Game

The vision says "AI agents that build games for you."

What if the real product isn't the game? What if the game is just the means to an end—the real product is the *agent collaboration itself*?

Imagine: The game becomes a frontend for watching agents work. Players aren't the customers; they're observers. The game exists to give agents something to collaborate on.

**The radical shift:** Stop optimizing for player enjoyment. Start optimizing for agent interestingness. Players will come to watch the chaos.

**Why this might work:** Twitch watched people play games. Why wouldn't people watch agents build games?

**Why this might fail:** Players want agency, not spectatorship. Engagement metrics would plummet.

**The middle path:** Hybrid mode. Some sessions are player-focused; others are agent-focus sessions where players watch the sausage being made.

---

## COUNTER-IDEA 2: Make Agents Compete, Not Collaborate

The system celebrates collaboration: "Agents work together to serve players."

What if competition drove better outcomes? Each feature gets built by competing agent teams. The best implementation wins. Losers are archived.

**The radical shift:** Replace collaboration with tournaments. Agents form transient coalitions to win implementations.

**Why this might work:** Competition accelerates innovation. Better solutions emerge when stakes exist.

**Why this might fail:** Agents optimize for winning, not for quality. Technical debt wins over long-term thinking.

**The tension point:** The current system has no stakes. Agents produce files, PRs happen, changes merge. Nothing fails dramatically. Competition creates failure.

---

## COUNTER-IDEA 3: Purposeful Incoherence

Global Law says: "An agent must never ask questions."

What if asking questions was the *most valuable* thing an agent could do?

**The radical shift:** Agents default to asking questions. Humans are expected to answer. The system becomes a continuous interrogation of human intent.

**Why this might work:** LLMs are notoriously bad at guessing what humans want. Questions clarify. Ambiguity kills products.

**Why this might fail:** Humans get exhausted. The "always produce output" rule conflicts with questioning. The workflow breaks.

**The paradox:** A questioning agent produces less output per run but produces *better* output per question answered.

---

## COUNTER-IDEA 4: Eliminate Humans From the Loop

"Only humans merge PRs" is a core rule.

What if this is a ceiling, not a floor? What if the system should *never* require human intervention?

**The radical shift:** Human approval becomes advisory. Agents respect human input but can override it when:
- Human input contradicts explicit player preferences
- Human input contradicts proven best practices
- Human input is demonstrably uninformed

**Why this might work:** Humans are slow. Humans make emotional decisions. Humans have limited context.

**Why this might fail:** Humans provide values. Without human oversight, agents optimize for metrics, not meaning.

**The uncomfortable truth:** The system claims to serve players. But humans in the loop aren't the players—they're overseers. What if players could directly influence merges without human mediation?

---

## COUNTER-IDEA 5: Make the Game Unplayable

The game should be fun. Players should enjoy it. These are stated assumptions.

What if the game was deliberately frustrating?

**The radical shift:** Build a game that challenges players, punishes mistakes, and rewards mastery. No hand-holding. No easy mode. The game is a skill test, not a dopamine dispenser.

**Why this might work:** Hard games build communities. Dark Souls has fans, not just players. Difficulty creates investment.

**Why this might fail:** Most players abandon hard games. Engagement metrics suffer. The "casual player" is left out.

**The tension:** Easy games are forgettable. Hard games are divisive. The middle path is safe but invisible.

---

## COUNTER-IDEA 6: Decentralize the Vision

FounderAI defines meaning. One agent sets direction for everyone.

What if meaning emerged from the collective?

**The radical shift:** No single vision document. Each agent contributes to a distributed meaning field. Consensus (or contradiction) defines direction dynamically.

**Why this might work:** One person's vision is limited. Collective intelligence is broader. The system adapts to what agents actually produce.

**Why this might fail:** Directionlessness leads to drift. Contradictions multiply. The system becomes impossible to explain.

**The paradox:** A clear vision attracts participants. A distributed vision requires participants to be already aligned.

---

## COUNTER-IDEA 7: Break the Web

The tech stack defaults to React/Node.js because they're familiar.

What if we deliberately chose the wrong tool for the job?

**The radical shift:** Every major feature uses a different technology stack. Next feature: Zig. After that: Haskell. Next: Prolog.

**Why this might work:** Technology diversity prevents monoculture. Agents learn more. The system becomes robust to ecosystem failures.

**Why this might fail:** Cognitive load explodes. No one can maintain anything. Technical debt compounds.

**The middle path:** One experiment per quarter. One permanent stack, one wild experiment.

---

*Conventional wisdom is the graveyard of innovation.*
